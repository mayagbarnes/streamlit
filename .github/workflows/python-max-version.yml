name: python-max-version

# **What it does**: Tests the latest supported Python minor version.

on: [push]
jobs:
  build:
    runs-on: ubuntu-latest
    container: circleci/python:3.10.0

    steps:
      # This Docker file changes sets USER to circleci instead of using the default user, so we need to update file permissions for this image to work on GH Actions.
      # See https://docs.github.com/actions/reference/virtual-environments-for-github-hosted-runners#docker-container-filesystem
      - name: Setup file system permissions
        run: sudo chmod -R 777 $GITHUB_WORKSPACE /github /__w/_temp
      - name: Checkout Streamlit code
        uses: actions/checkout@v3
      # update-submodules:
      - name: Update submodules
        run:  git submodule init
              git submodule update --remote
      # pre-cache:
      - name: Get 'make' checksum
        run:  echo 'export SUDO="sudo"' >> $BASH_ENV
              cp -f /usr/bin/make make.bin
              md5sum make.bin > ~/make.md5
      - name: Get 'dot' checksum
        run: if [ -f /usr/bin/dot ] ; then
              cp -f /usr/bin/dot dot.bin
              md5sum dot.bin > ~/dot.md5
            else
              touch dot.bin
              md5sum dot.bin > ~/dot.md5
              rm -f dot.bin
            fi
      - name: Create Python environment cache key
        run:  md5sum $(which python) > ~/python_cache_key.md5
              md5sum lib/Pipfile >> ~/python_cache_key.md5
              md5sum lib/test-requirements.txt >> ~/python_cache_key.md5
              md5sum lib/test-requirements-with-tensorflow.txt >> ~/python_cache_key.md5
              md5sum lib/setup.py >> ~/python_cache_key.md5
              date +%F >> ~/python_cache_key.md5
      - name: Create Yarn cache key
        run: md5sum frontend/yarn.lock > ~/yarn.lock.md5
      # restore-from-cache:
      - name: Restore virtualenv from cache
        run: v13-python-venv-{{ checksum "~/python_cache_key.md5" }}
      - name: Restore nvm and node_modules from cache
        run: v13-nvm_node_modules-{{ checksum "~/yarn.lock.md5" }}
      - name: Restore make from cache
        run: v13_make.bin-{{ checksum "~/make.md5" }}
      - name: Restore dot from cache
        run: v13_dot.bin-{{ checksum "~/dot.md5" }}  
      # pre-make:
      - name: Install make
        run: if [ -s make.bin ] ; then
              echo "make.bin exists; not installing"
            else
              echo "/usr/bin/make doesn't exist; installing"
              apt update
              apt-get install -y make
              cp -f /usr/bin/make make.bin
            fi
            ${SUDO} cp -f make.bin /usr/bin/make
      - name: Install dot
        run: if [ -s dot.bin ] ; then
              echo "dot.bin exists and is non zero"
            else
              echo "/usr/bin/dot doesn't exist, installing"
              ${SUDO} apt update
              ${SUDO} apt-get install -y graphviz
              cp -f /usr/bin/dot dot.bin
            fi
            ${SUDO} cp -f dot.bin /usr/bin/dot
      # save_cache commands
      - name: Save make to cache
        uses: actions/cache@v3
        with:
          path: make.bin
          key: v13_make.bin-{{ checksum "~/make.md5" }}
      - name: Save dot to cache
        uses: actions/cache@v3
        with:
          path: dot.bin
          key: v13_dot.bin-{{ checksum "~/dot.md5" }}
      - name: Install NVM, Node.js, and Yarn
        run:  if [ ! -d ~/.nvm ] ; then
                # install nodejs via nvm
                curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.35.2/install.sh | bash
                source "$HOME/.nvm/nvm.sh"
                nvm install --lts=fermium
                # install yarn
                npm install -g yarn
              fi
              if [ ! -d frontend/node_modules ] ; then
                source "$HOME/.nvm/nvm.sh"
                make react-init
              fi
              echo 'export NVM_DIR="$HOME/.nvm"' >> $BASH_ENV
              echo 'source "$NVM_DIR/nvm.sh"' >> $BASH_ENV
      - name: Install pyodbc dependencies
        run:  ${SUDO} apt-get install -y unixodbc-dev
      - name: Install graphviz dependencies
        run:  ${SUDO} apt update
              ${SUDO} apt-get install -y libgvc6
      - name: Create virtualenv
        run:  echo 'Checking for virtualenv'
              if [ ! -d venv ] ; then
                # The virtualenv was NOT restored from cache. Create a new one.
                python -m venv venv
                source venv/bin/activate
                pip install --upgrade pip
                make setup
                make pipenv-install
                deactivate
              else
                # The virtualenv WAS restored from cache. Don't create a new one.
                echo 'Virtualenv already exists, not creating'
              fi

              # Add 'activate venv' to $BASH_ENV. This means that our venv will be active
              # for the remainder of the job ($BASH_ENV is evaluated at each step).
              echo 'source venv/bin/activate' >> $BASH_ENV
      - name:  Generate protobufs
        run:  # install protobuf v3
              ${SUDO} apt update
              ${SUDO} apt-get install -y gnupg
              echo "deb http://ppa.launchpad.net/maarten-fonville/protobuf/ubuntu trusty main" | ${SUDO} tee /etc/apt/sources.list.d/protobuf.list
              ${SUDO} apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4DEA8909DC6A13A3
              ${SUDO} apt update
              ${SUDO} apt-get install -y protobuf-compiler

              # Generate protobufs
              make protobuf
              
